{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_dot_in_place(file_path):\n",
    "    # Read the lines from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Process each line to remove the leading dot\n",
    "    lines = [line[1:] if line.startswith('.') else line for line in lines]\n",
    "    \n",
    "    # Write the processed lines back to the same file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "file_path = '/home/moe/Desktop/dof/output_transformer (1).txt'  # Replace with your file name\n",
    "\n",
    "remove_leading_dot_in_place(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "79\n",
      "CSV file created at: output_with_transformers.csv\n",
      "CSV file created at: output_with_transformers.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Define the filename\n",
    "#filename = 'output_with_waveNet.txt'\n",
    "filename = '/home/moe/Desktop/dof/output_transformer (1).txt'\n",
    "#filename = 'output_with_batch.txt'\n",
    "#filename = 'output_without_batch.txt'\n",
    "# Initialize an empty list to store the strings\n",
    "L = []\n",
    "\n",
    "# Read from the file\n",
    "with open(filename, 'r') as file:\n",
    "    for line in file:\n",
    "        # Strip newline characters from the end of each line\n",
    "        L.append(line.strip())\n",
    "\n",
    "# Optionally, print the list to verify the contents\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "intervals = {\n",
    "    'a': (0.0, 0.11244552352705767),\n",
    "    'b': (0.11244552352705767, 0.6673535845977986),\n",
    "    'c': (0.6673535845977986, 1.0),\n",
    "    'd': (1.0, 2.0),\n",
    "    'e': (2.0, 3.0),\n",
    "    'f': (3.0, 3.559489622105667),\n",
    "    'g': (3.559489622105667, 6.0),\n",
    "    'h': (6.0, 9.581268828803156),\n",
    "    'i': (9.581268828803156, 11.0),\n",
    "    'j': (11.0, 17.0),\n",
    "    'k': (17.0, 20.0),\n",
    "    'l': (20.0, 40.0),\n",
    "    'm': (40.0, 60.0),\n",
    "    'n': (60.0, 74.0),\n",
    "    'o': (74.0, 89.88980835439897),\n",
    "    'p': (89.88980835439897, 112.0),\n",
    "    'q': (112.0, 148.0),\n",
    "    'r': (148.0, 199.0),\n",
    "    's': (199.0, 296.0),\n",
    "    't': (296.0, 2521.8522647163813),\n",
    "    'u': (2521.8522647163813, 4096.0),\n",
    "    'v': (4096.0, 5780.346820809248),\n",
    "    'w': (5780.346820809248, 8196.72131147541),\n",
    "    'x': (8196.72131147541, 9803.921568627453),\n",
    "    'y': (9803.921568627453, 11264.0),\n",
    "    'z': (11264.0, 13513.513513513511),\n",
    "    'a1': (13513.513513513511, 18122.0),\n",
    "    'b1': (18122.0, 28571.42857142857),\n",
    "    'c1': (28571.42857142857, 37642.0),\n",
    "    'd1': (37642.0, 43838.140000000014),\n",
    "    'e1': (43838.140000000014, 51634.0),\n",
    "    'f1': (51634.0, 57154.50152098043),\n",
    "    'g1': (57154.50152098043, 70181.3128153594),\n",
    "    'h1': (70181.3128153594, 187613.0),\n",
    "    'i1': (187613.0, 285987.0),\n",
    "    'j1': (285987.0, 377213.5700000002),\n",
    "    'k1': (377213.5700000002, 507936.50793650793),\n",
    "    'l1': (507936.50793650793, 661913.6),\n",
    "    'm1': (661913.6, 895104.8951048951),\n",
    "    'n1': (895104.8951048951, 1034389.0300000045),\n",
    "    'o1': (1034389.0300000045, 1219047.619047619),\n",
    "    'p1': (1219047.619047619, 1671964.5127806715),\n",
    "    'q1': (1671964.5127806715, 2825195.0),\n",
    "    'r1': (2825195.0, 3312339.5000000056),\n",
    "    's1': (3312339.5000000056, 5110005.194339051),\n",
    "    't1': (5110005.194339051, 8259176.825999905),\n",
    "    'u1': (8259176.825999905, 14358868.141890742),\n",
    "    'v1': (14358868.141890742, 26460339.300000004),\n",
    "    'w1': (26460339.300000004, 125961768.0),\n",
    "}\n",
    "\n",
    "modified = []    \n",
    "for x in L:\n",
    "    toreturn = []\n",
    "    i = 0\n",
    "    while i < len(x):\n",
    "        # If the next character is a digit, combine it with the current character\n",
    "        if i+1 < len(x) and x[i+1].isdigit():\n",
    "            s = x[i] + x[i+1]\n",
    "            i += 2 # Skip the next character since it's combined\n",
    "        else:\n",
    "            s = x[i]\n",
    "            i += 1 # Move to the next character\n",
    "        toreturn.append(s)\n",
    "    modified.append(toreturn)  \n",
    "print(len(modified[0]))   \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Column names provided\n",
    "column_names = [\n",
    "    \"src_port\", \"dst_port\", \"protocol\", \"flow_duration\", \"flow_byts_s\",\n",
    "    \"flow_pkts_s\", \"fwd_pkts_s\", \"bwd_pkts_s\", \"tot_fwd_pkts\", \"tot_bwd_pkts\",\n",
    "    \"totlen_fwd_pkts\", \"totlen_bwd_pkts\", \"fwd_pkt_len_max\", \"fwd_pkt_len_min\",\n",
    "    \"fwd_pkt_len_mean\", \"fwd_pkt_len_std\", \"bwd_pkt_len_max\", \"bwd_pkt_len_min\",\n",
    "    \"bwd_pkt_len_mean\", \"bwd_pkt_len_std\", \"pkt_len_max\", \"pkt_len_min\",\n",
    "    \"pkt_len_mean\", \"pkt_len_std\", \"pkt_len_var\", \"fwd_header_len\",\n",
    "    \"bwd_header_len\", \"fwd_seg_size_min\", \"fwd_act_data_pkts\", \"flow_iat_mean\",\n",
    "    \"flow_iat_max\", \"flow_iat_min\", \"flow_iat_std\", \"fwd_iat_tot\",\n",
    "    \"fwd_iat_max\", \"fwd_iat_min\", \"fwd_iat_mean\", \"fwd_iat_std\", \"bwd_iat_tot\",\n",
    "    \"bwd_iat_max\", \"bwd_iat_min\", \"bwd_iat_mean\", \"bwd_iat_std\", \"fwd_psh_flags\",\n",
    "    \"bwd_psh_flags\", \"fwd_urg_flags\", \"bwd_urg_flags\", \"fin_flag_cnt\",\n",
    "    \"syn_flag_cnt\", \"rst_flag_cnt\", \"psh_flag_cnt\", \"ack_flag_cnt\",\n",
    "    \"urg_flag_cnt\", \"ece_flag_cnt\", \"down_up_ratio\", \"pkt_size_avg\",\n",
    "    \"init_fwd_win_byts\", \"init_bwd_win_byts\", \"active_max\", \"active_min\",\n",
    "    \"active_mean\", \"active_std\", \"idle_max\", \"idle_min\", \"idle_mean\", \"idle_std\",\n",
    "    \"fwd_byts_b_avg\", \"fwd_pkts_b_avg\", \"bwd_byts_b_avg\", \"bwd_pkts_b_avg\",\n",
    "    \"fwd_blk_rate_avg\", \"bwd_blk_rate_avg\", \"fwd_seg_size_avg\", \"bwd_seg_size_avg\",\n",
    "    \"cwe_flag_count\", \"subflow_fwd_pkts\", \"subflow_bwd_pkts\", \"subflow_fwd_byts\",\n",
    "    \"subflow_bwd_byts\"\n",
    "]  \n",
    "print(len(column_names))\n",
    "default_ev = {\n",
    "    \"dst_port\":80,\n",
    "    \"pkt_len_mean\": 1066,\n",
    "    \"pkt_len_std\": 0,\n",
    "    \"pkt_len_var\": 0,\n",
    "    \"bwd_header_len\": 0,\n",
    "    \"fwd_seg_size_min\": 8,\n",
    "    \"bwd_iat_tot\": 0,\n",
    "    \"bwd_iat_max\": 0,\n",
    "    \"bwd_iat_min\": 0,\n",
    "    \"bwd_iat_mean\": 0,\n",
    "    \"bwd_iat_std\": 0,\n",
    "    \"fwd_psh_flags\": 0,\n",
    "    \"bwd_psh_flags\": 0,\n",
    "    \"fwd_urg_flags\": 0,\n",
    "    \"bwd_urg_flags\": 0,\n",
    "    \"fin_flag_cnt\": 1,\n",
    "    \"syn_flag_cnt\": 0,\n",
    "    \"rst_flag_cnt\": 0,\n",
    "    \"psh_flag_cnt\": 0,\n",
    "    \"ack_flag_cnt\": 0,\n",
    "    \"urg_flag_cnt\": 0,\n",
    "    \"ece_flag_cnt\": 0,\n",
    "    \"down_up_ratio\": 0,\n",
    "    \"pkt_size_avg\": 1066,\n",
    "    \"init_fwd_win_byts\": 0,\n",
    "    \"init_bwd_win_byts\": 0,\n",
    "    \"active_max\": 0,\n",
    "    \"active_min\": 0,\n",
    "    \"active_mean\": 0,\n",
    "    \"active_std\": 0,\n",
    "    \"idle_max\": 0,\n",
    "    \"idle_min\": 0,\n",
    "    \"idle_mean\": 0,\n",
    "    \"idle_std\": 0,\n",
    "    \"bwd_byts_b_avg\": 0,\n",
    "    \"bwd_pkts_b_avg\": 0,\n",
    "    \"bwd_blk_rate_avg\": 0,\n",
    "    \"fwd_seg_size_avg\": 1066,\n",
    "    \"bwd_seg_size_avg\": 0,\n",
    "    \"cwe_flag_count\": 0,\n",
    "    \"subflow_bwd_pkts\": 0,\n",
    "    \"subflow_bwd_byts\": 0\n",
    "}\n",
    "def make_csv(column_names, modified, intervals, default_ev):\n",
    "    # Initialize a DataFrame with the correct shape but empty\n",
    "    df = pd.DataFrame(index=range(len(modified)), columns=column_names)\n",
    "    \n",
    "    for row_idx, row in enumerate(modified):\n",
    "        for col_idx, element in enumerate(row):\n",
    "          \n",
    "            col_name = column_names[col_idx]\n",
    "            if col_name in default_ev:\n",
    "                # Use the default value for columns defined in default_ev\n",
    "                df.at[row_idx, col_name] = default_ev[col_name]\n",
    "            else:\n",
    "                # Sample a value for other columns based on the first character of the element\n",
    "                interval = intervals.get(element , (0, 1))  # Default interval\n",
    "                df.at[row_idx, col_name] = np.random.uniform(interval[0], interval[1])\n",
    "    \n",
    "    # Save to CSV\n",
    "    #csv_file_path = 'output_with_waveNet.csv'\n",
    "    csv_file_path = 'output_with_transformers.csv'\n",
    "    #csv_file_path = 'output_with_batch.csv'\n",
    "    #csv_file_path = 'output_without_batch.csv'\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    return csv_file_path\n",
    "\n",
    "# Assuming column_names, intervals, and default_ev are defined as before\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = make_csv(column_names, modified, intervals, default_ev)\n",
    "print(f\"CSV file created at: {csv_file_path}\") \n",
    "\n",
    "# Example usage\n",
    "csv_file_path = make_csv(column_names, modified, intervals, default_ev)\n",
    "print(f\"CSV file created at: {csv_file_path}\")\n",
    "#pseudocde for makeme \n",
    "# for each row in modified  \n",
    "# loop over each element   \n",
    "# according to the index of the element , assign the value to the corresponding column name   \n",
    "# get the value by two ways \n",
    "# if the corresponding col  in default interval , get the value from the default_ev dictionary   \n",
    "#else get the value from the intervals dictionary by sampling uniformly from the interval \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file does not contain any missing or NaN values.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_missing_values(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum().sum()\n",
    "    \n",
    "    if missing_values > 0:\n",
    "        print(f'The file contains {missing_values} missing or NaN values.')\n",
    "    else:\n",
    "        print('The file does not contain any missing or NaN values.')\n",
    "\n",
    "file_path = '/home/moe/Desktop/dof/output_with_transformers.csv'  # Replace with your CSV file name\n",
    "\n",
    "check_missing_values(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
